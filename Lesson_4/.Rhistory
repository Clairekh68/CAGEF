text_table <- data.frame(
Expression = c("\\w, [A-z0-9], [[:alnum:]]", "\\d, [0-9], [[:digit:]]", "[A-z], [:alpha:]", "\\s, [[:space:]]", "[[:punct:]]", "[[:lower:]]", "[[:upper:]]", "\\W, [^A-z0-9]", "\\S", "\\D, [^0-9]"),
Meaning = c("word characters (letters + digits)", "digits", "alphabetical characters", "space", "punctuation", "lowercase", "uppercase", "not word characters", "not space", "not digits")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("|", ".", "[  ]", "[ - ]", "[^ ]", "( )"),
Meaning = c("or", "matches any single character", "matches ANY of the characters inside the brackets", "matches a RANGE of characters inside the brackets", "matches any character EXCEPT those inside the bracket", "grouping - used for _backreferencing_")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("\\"),
Meaning = c("escape! necessary to use special meta-characters (*, $, ^, ., ?, |, \\, [, ], {, }, (, )) [Note that the backslash is a meta-character as well]")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
library(tidyverse)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F)
str(elon_tweets_df)
elon_tweets_df <- elon_tweets_df %>% arrange(desc(favoriteCount))
elon_tweets_df$text[1:5]
tags <- "#|@\\w+"
grep(pattern = tags, x = elon_tweets_df$text)
grep(tags, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = tags, replacement = "", elon_tweets_df$text)
iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub="") %>% head()
elon_tweets_df$text <- iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub = "")
url <- "http[s]?://[[:alnum:].\\/]+"
grep(url, elon_tweets_df$text, value = TRUE) %>% head()
grepl(url, elon_tweets_df$text) %>% head()
elon_urls <- elon_tweets_df %>% filter(grepl(url, elon_tweets_df$text))
elon_tweets_df$text <- gsub(pattern = "http[s]?://[[:alnum:].\\/]+", replacement = "", elon_tweets_df$text)
trail <- "[ ]+$"
grep(trail, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = "[ ]+$", replacement = "", elon_tweets_df$text)
trail <- "[ ]+$|[0-9]*|[[:punct:]]"
grep(trail, elon_tweets_df$text, value = TRUE) %>% head()
trail <- "[ ]+$|[0-9]*|[[:punct:]]"
elon_tweets_df$text <- gsub(pattern = trail, replacement = "", elon_tweets_df$text)
elon_tweets_df$text[1:5]
trail <- "[ ]+$|[0-9]*|[[:punct:]][  ]"
elon_tweets_df$text <- gsub(pattern = trail, replacement = "", elon_tweets_df$text)
elon_tweets_df$text[1:5]
space <- "\\s{2,}"
grep(space, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = space, replacement = "\\s", elon_tweets_df$text)
elon_tweets_df$text[1:5]
elon_tweets_df$text <- gsub(pattern = space, replacement = "\\s.", elon_tweets_df$text)
elon_tweets_df$text[1:5]
library(knitr)
library(kableExtra)
text_table <- data.frame(
Expression = c("^", "$", "\\b", "\\B"),
Meaning = c("start of string", "end of string", "empty string at either edge of a word", "empty string that is NOT at the edge of a word")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("?", "*","+", "{n}", "{n,}", "{,n}", "{n,m}"),
Meaning = c("0 or 1", "0 or more", "1 or more", "exactly n", "at least n", "at most n", "between n and m (inclusive)")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("\\w, [A-z0-9], [[:alnum:]]", "\\d, [0-9], [[:digit:]]", "[A-z], [:alpha:]", "\\s, [[:space:]]", "[[:punct:]]", "[[:lower:]]", "[[:upper:]]", "\\W, [^A-z0-9]", "\\S", "\\D, [^0-9]"),
Meaning = c("word characters (letters + digits)", "digits", "alphabetical characters", "space", "punctuation", "lowercase", "uppercase", "not word characters", "not space", "not digits")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("|", ".", "[  ]", "[ - ]", "[^ ]", "( )"),
Meaning = c("or", "matches any single character", "matches ANY of the characters inside the brackets", "matches a RANGE of characters inside the brackets", "matches any character EXCEPT those inside the bracket", "grouping - used for _backreferencing_")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("\\"),
Meaning = c("escape! necessary to use special meta-characters (*, $, ^, ., ?, |, \\, [, ], {, }, (, )) [Note that the backslash is a meta-character as well]")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
library(tidyverse)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F)
str(elon_tweets_df)
elon_tweets_df <- elon_tweets_df %>% arrange(desc(favoriteCount))
elon_tweets_df$text[1:5]
tags <- "#|@\\w+"
grep(pattern = tags, x = elon_tweets_df$text)
grep(tags, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = tags, replacement = "", elon_tweets_df$text)
iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub="") %>% head()
elon_tweets_df$text <- iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub = "")
url <- "http[s]?://[[:alnum:].\\/]+"
grep(url, elon_tweets_df$text, value = TRUE) %>% head()
grepl(url, elon_tweets_df$text) %>% head()
elon_urls <- elon_tweets_df %>% filter(grepl(url, elon_tweets_df$text))
elon_tweets_df$text <- gsub(pattern = "http[s]?://[[:alnum:].\\/]+", replacement = "", elon_tweets_df$text)
trail <- "[ ]+$|[0-9]*|[[:punct:]]"
grep(trail, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = trail, replacement = "", elon_tweets_df$text)
elon_tweets_df$text[1:5]
elon_tweets_df$text <- gsub(pattern = space, replacement = "\\s.", elon_tweets_df$text)
elon_tweets_df$text[1:5]
library(knitr)
library(kableExtra)
text_table <- data.frame(
Expression = c("^", "$", "\\b", "\\B"),
Meaning = c("start of string", "end of string", "empty string at either edge of a word", "empty string that is NOT at the edge of a word")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("?", "*","+", "{n}", "{n,}", "{,n}", "{n,m}"),
Meaning = c("0 or 1", "0 or more", "1 or more", "exactly n", "at least n", "at most n", "between n and m (inclusive)")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("\\w, [A-z0-9], [[:alnum:]]", "\\d, [0-9], [[:digit:]]", "[A-z], [:alpha:]", "\\s, [[:space:]]", "[[:punct:]]", "[[:lower:]]", "[[:upper:]]", "\\W, [^A-z0-9]", "\\S", "\\D, [^0-9]"),
Meaning = c("word characters (letters + digits)", "digits", "alphabetical characters", "space", "punctuation", "lowercase", "uppercase", "not word characters", "not space", "not digits")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("|", ".", "[  ]", "[ - ]", "[^ ]", "( )"),
Meaning = c("or", "matches any single character", "matches ANY of the characters inside the brackets", "matches a RANGE of characters inside the brackets", "matches any character EXCEPT those inside the bracket", "grouping - used for _backreferencing_")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("\\"),
Meaning = c("escape! necessary to use special meta-characters (*, $, ^, ., ?, |, \\, [, ], {, }, (, )) [Note that the backslash is a meta-character as well]")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
library(tidyverse)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F)
str(elon_tweets_df)
elon_tweets_df <- elon_tweets_df %>% arrange(desc(favoriteCount))
elon_tweets_df$text[1:5]
tags <- "#|@\\w+"
grep(pattern = tags, x = elon_tweets_df$text)
grep(tags, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = tags, replacement = "", elon_tweets_df$text)
iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub="") %>% head()
elon_tweets_df$text <- iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub = "")
url <- "http[s]?://[[:alnum:].\\/]+"
grep(url, elon_tweets_df$text, value = TRUE) %>% head()
grepl(url, elon_tweets_df$text) %>% head()
elon_urls <- elon_tweets_df %>% filter(grepl(url, elon_tweets_df$text))
elon_tweets_df$text <- gsub(pattern = "http[s]?://[[:alnum:].\\/]+", replacement = "", elon_tweets_df$text)
trail <- "[ ]+$|[0-9]*|[[:punct:]]"
grep(trail, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = trail, replacement = "", elon_tweets_df$text)
elon_tweets_df$text[1:5]
elon_tweets_df$text <- gsub(pattern = space, replacement = "[[:space:]]", elon_tweets_df$text)
elon_tweets_df$text[1:5]
library(knitr)
library(kableExtra)
text_table <- data.frame(
Expression = c("^", "$", "\\b", "\\B"),
Meaning = c("start of string", "end of string", "empty string at either edge of a word", "empty string that is NOT at the edge of a word")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("?", "*","+", "{n}", "{n,}", "{,n}", "{n,m}"),
Meaning = c("0 or 1", "0 or more", "1 or more", "exactly n", "at least n", "at most n", "between n and m (inclusive)")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("\\w, [A-z0-9], [[:alnum:]]", "\\d, [0-9], [[:digit:]]", "[A-z], [:alpha:]", "\\s, [[:space:]]", "[[:punct:]]", "[[:lower:]]", "[[:upper:]]", "\\W, [^A-z0-9]", "\\S", "\\D, [^0-9]"),
Meaning = c("word characters (letters + digits)", "digits", "alphabetical characters", "space", "punctuation", "lowercase", "uppercase", "not word characters", "not space", "not digits")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("|", ".", "[  ]", "[ - ]", "[^ ]", "( )"),
Meaning = c("or", "matches any single character", "matches ANY of the characters inside the brackets", "matches a RANGE of characters inside the brackets", "matches any character EXCEPT those inside the bracket", "grouping - used for _backreferencing_")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("\\"),
Meaning = c("escape! necessary to use special meta-characters (*, $, ^, ., ?, |, \\, [, ], {, }, (, )) [Note that the backslash is a meta-character as well]")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
library(tidyverse)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F)
str(elon_tweets_df)
elon_tweets_df <- elon_tweets_df %>% arrange(desc(favoriteCount))
elon_tweets_df$text[1:5]
tags <- "#|@\\w+"
grep(pattern = tags, x = elon_tweets_df$text)
grep(tags, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = tags, replacement = "", elon_tweets_df$text)
iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub="") %>% head()
elon_tweets_df$text <- iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub = "")
url <- "http[s]?://[[:alnum:].\\/]+"
grep(url, elon_tweets_df$text, value = TRUE) %>% head()
grepl(url, elon_tweets_df$text) %>% head()
elon_urls <- elon_tweets_df %>% filter(grepl(url, elon_tweets_df$text))
elon_tweets_df$text <- gsub(pattern = "http[s]?://[[:alnum:].\\/]+", replacement = "", elon_tweets_df$text)
trail <- "[ ]+$|[0-9]*|[[:punct:]]"
grep(trail, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = trail, replacement = "", elon_tweets_df$text)
elon_tweets_df$text[1:5]
elon_tweets_df$text <- gsub(pattern = space, replacement = " ", elon_tweets_df$text)
elon_tweets_df$text[1:5]
extra <- "^[ ]"
grep(extra, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = extra, replacement = " ", elon_tweets_df$text)
elon_tweets_df$text[1:5]
extra <- "^[ ]"
grep(extra, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = extra, replacement = "", elon_tweets_df$text)
elon_tweets_df$text[1:5]
strsplit(elon_tweets_df$text, " ")
str(strsplit(elon_tweets_df$text, split = " "))
unlist(strsplit(elon_tweets_df$text, split = " "))
str(unlist(strsplit(elon_tweets_df$text, split = " ")))
unlist(strsplit(elon_tweets_df$text, split = " "))
words <- unlist(strsplit(elon_tweets_df$text, split = " "))
strsplit(words, "\\n")
unlist(strsplit(words, "\\n"))
gsub(words, "[[:lower:]]")
gsub(words, "[[:lower:]]", words)
words <- tolower(unlist(strsplit(words, "\\n")))
words
words <- casefold(unlist(strsplit(words, "\\n")), upper = TRUE)
words <- casefold(unlist(strsplit(words, "\\n")), upper = FALSE)
head(words)
words[1:50]
tail(words)
tail(words)
tail(words, 50)
words <- tolower(unlist(strsplit(words, "\\")))
words <- tolower(unlist(strsplit(words, "\\\")))
words <- tolower(unlist(strsplit(words, "\\\\")))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "\\")))
words <- tolower(unlist(strsplit(words, "[\\]")))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "[\\\\]")))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "[\\\\]", fixed = FALSE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "[\\]", fixed = FALSE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "[\]", fixed = FALSE)))
words <- tolower(unlist(strsplit(words, "\\", fixed = FALSE)))
words <- tolower(unlist(strsplit(words, "\\\\", fixed = FALSE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "\\\\", fixed = TRUE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "\\\\", fixed = TRUE, perl = TRUE)))
words <- tolower(unlist(strsplit(words, "\\\\",  perl = TRUE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "[\\\\]",  perl = TRUE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "[\\\\]|[^[:print:]]", fixed = FALSE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "\\n|\\t")))
tail(words, 50)
library(knitr)
library(kableExtra)
text_table <- data.frame(
Expression = c("^", "$", "\\b", "\\B"),
Meaning = c("start of string", "end of string", "empty string at either edge of a word", "empty string that is NOT at the edge of a word")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("?", "*","+", "{n}", "{n,}", "{,n}", "{n,m}"),
Meaning = c("0 or 1", "0 or more", "1 or more", "exactly n", "at least n", "at most n", "between n and m (inclusive)")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("\\w, [A-z0-9], [[:alnum:]]", "\\d, [0-9], [[:digit:]]", "[A-z], [:alpha:]", "\\s, [[:space:]]", "[[:punct:]]", "[[:lower:]]", "[[:upper:]]", "\\W, [^A-z0-9]", "\\S", "\\D, [^0-9]"),
Meaning = c("word characters (letters + digits)", "digits", "alphabetical characters", "space", "punctuation", "lowercase", "uppercase", "not word characters", "not space", "not digits")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("|", ".", "[  ]", "[ - ]", "[^ ]", "( )"),
Meaning = c("or", "matches any single character", "matches ANY of the characters inside the brackets", "matches a RANGE of characters inside the brackets", "matches any character EXCEPT those inside the bracket", "grouping - used for _backreferencing_")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("\\"),
Meaning = c("escape! necessary to use special meta-characters (*, $, ^, ., ?, |, \\, [, ], {, }, (, )) [Note that the backslash is a meta-character as well]")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
library(tidyverse)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F)
str(elon_tweets_df)
elon_tweets_df <- elon_tweets_df %>% arrange(desc(favoriteCount))
elon_tweets_df$text[1:5]
tags <- "#|@\\w+"
grep(pattern = tags, x = elon_tweets_df$text)
grep(tags, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = tags, replacement = "", elon_tweets_df$text)
iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub="") %>% head()
elon_tweets_df$text <- iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub = "")
url <- "http[s]?://[[:alnum:].\\/]+"
grep(url, elon_tweets_df$text, value = TRUE) %>% head()
grepl(url, elon_tweets_df$text) %>% head()
elon_urls <- elon_tweets_df %>% filter(grepl(url, elon_tweets_df$text))
elon_tweets_df$text <- gsub(pattern = "http[s]?://[[:alnum:].\\/]+", replacement = "", elon_tweets_df$text)
trail <- "[ ]+$|[0-9]*|[[:punct:]]"
grep(trail, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = trail, replacement = "", elon_tweets_df$text)
elon_tweets_df$text[1:5]
space <- "\\s{2,}"
grep(space, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = space, replacement = " ", elon_tweets_df$text)
elon_tweets_df$text[1:5]
extra <- "^[ ]"
grep(extra, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = extra, replacement = "", elon_tweets_df$text)
elon_tweets_df$text[1:5]
strsplit(elon_tweets_df$text, split = " ")
str(strsplit(elon_tweets_df$text, split = " "))
words <- tolower(unlist(strsplit(words, "\\n|\\t")))
tail(words, 50)
tail(words, 50)
words[1:50]
tail(words, 50)
count(words)
count(as.factor(words))
n_groups(words)
n_groups(data.frame(words))
n_groups(data.frame(factor(words)))
test <- data.frame(words) %>% select(words) %>% count(factor(words)) %>% arrange(desc(n))
data.frame(words)
test <- data.frame(words) %>% count(factor(.)) %>% arrange(desc(n))
test <- data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
library(tidytext)
stop <- stop_words
View(stop)
str(stop)
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea"),
lexicon = "custom")
stop <- bind_rows(stop, add_stop)
stop <- stop_words
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea"),
lexicon = "custom")
stop <- bind_rows(stop, add_stop)
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea"),
lexicon = "custom", stringsAsFactors = FALSE)
stop <- bind_rows(stop, add_stop)
stop <- stop_words
stop <- bind_rows(stop, add_stop)
anti_join(words, stop, by=c("factor(value)" = "word"))
anti_join(data.frame(words), stop, by=c("factor(value)" = "word"))
anti_join(data.frame(words), stop, by=c("factor(words)" = "word"))
str(data.frame(words)
)
anti_join(data.frame(words), stop, by=c("words" = "word"))
words <- anti_join(data.frame(words), stop, by=c("words" = "word"))
words %>% count(words) %>% arrange(desc(n))
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea", "relnofollowtwitter"),
lexicon = "custom", stringsAsFactors = FALSE)
stop <- bind_rows(stop, add_stop)
stop <- stop_words
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea", "relnofollowtwitter"),
lexicon = "custom", stringsAsFactors = FALSE)
stop <- bind_rows(stop, add_stop)
words <- anti_join(data.frame(words), stop, by=c("words" = "word"))
words %>% count(words) %>% arrange(desc(n))
stop <- stop_words
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea", "relnofollowtwitter", "relnofollowinstagrama"),
lexicon = "custom", stringsAsFactors = FALSE)
stop <- bind_rows(stop, add_stop)
words <- anti_join(data.frame(words), stop, by=c("words" = "word"))
words %>% count(words) %>% arrange(desc(n))
nrc <- sentiments %>%
filter(lexicon == "nrc") %>%
dplyr::select(word, sentiment)
nrc
by_source_sentiment <- trump_words %>%
inner_join(nrc, by =c("factor(value)" = "word")) %>%
count(sentiment) %>%
arrange(desc(nn))
by_source_sentiment <- words %>%
inner_join(nrc, by =c("factor(value)" = "word")) %>%
count(sentiment) %>%
arrange(desc(nn))
by_source_sentiment <- words %>%
inner_join(nrc, by =c("words" = "word")) %>%
count(sentiment) %>%
arrange(desc(nn))
by_source_sentiment <- words %>%
inner_join(nrc, by =c("words" = "word")) %>%
count(sentiment) %>%
arrange(desc(n))
head(by_source_sentiment)
library("wordcloud")
library("viridis")
words %>%
top_n(50) %>%
with(wordcloud(word, n, ordered.colors = TRUE, colors = viridis(61), use.r.layout = TRUE))
length(words %>% top_n(50))
words <- words %>% count(words) %>% arrange(desc(n))
words %>%
top_n(50) %>%
with(wordcloud(word, n, ordered.colors = TRUE, colors = viridis(61), use.r.layout = TRUE))
length(words %>% top_n(50))
words %>%
top_n(50) %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(61), use.r.layout = TRUE))
words %>%
with(wordcloud(words[1:50,], n, ordered.colors = TRUE, colors = viridis(61), use.r.layout = TRUE))
words[1:50,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(61), use.r.layout = TRUE))
str(words[1:50,])
words[1:50,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(50), use.r.layout = TRUE))
words[2:50,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(50), use.r.layout = TRUE))
words[2:50,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(49), use.r.layout = TRUE))
words[1:50,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(50), use.r.layout = TRUE))
trump_tweets_df <- read.delim("data/trump_tweets_df.txt", sep = "\t")
trump_tweets_df <- trump_tweets_df %>% arrange(desc(favoriteCount))
trump_tweets_df$text[1:5]
str_detect(trump_tweets_df$text, tags)
str_locate(trump_tweets_df$text, tags)
str_extract(trump_tweets_df$text, tags)
str_extract(trump_tweets_df$text, tags)
str_extract_all(string = trump_tweets_df$text, pattern = tags)
str_extract(string = trump_tweets_df$text, pattern = tags)
str_detect(trump_tweets_df$text, tags)
str_detect(trump_tweets_df$text, tags)
save <- str_extract_all(trump_tweets_df$text, "[#|@|[:alnum:]]+([^\\s][[:alnum:]]+)?", simplify = TRUE)
View(save)
trump_tweets_df$text[1]
trump_tweets_df$text[2]
url
tags
clean <- "http[s]?://[[:alnum:].\\/]+|#|@\\w+|[0-9]*|\\n|\\t"
clean <- "http[s]?://[[:alnum:].\\/]+|#|@\\w+|[0-9]*|\\n|\\t|[[:punct:]]"
str_remove(trump_tweets_df$text, clean, "")
str_remove(trump_tweets_df$text, pattern = clean, replacement = "")
str_remove(trump_tweets_df$text, pattern = clean)
clean <- "(http[s]?://[[:alnum:].\\/]+)|(#|@\\w+)|([0-9]*)|\\n|\\t|[[:punct:]]"
str_remove(trump_tweets_df$text[1:5], pattern = clean)
clean <- "[[[punct:]]"
rm(nrc)
rm(save)
clean <- "[[punct:]]"
str_remove(trump_tweets_df$text[1:5], pattern = clean)
clean <- "[[:punct:]]"
str_remove(trump_tweets_df$text[1:5], pattern = clean)
str_remove(trump_tweets_df$text[1:5], pattern = urls)
str_remove(trump_tweets_df$text[1:5], pattern = url)
url
