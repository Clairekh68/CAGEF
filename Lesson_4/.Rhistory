column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("\\"),
Meaning = c("escape! necessary to use special meta-characters (*, $, ^, ., ?, |, \\, [, ], {, }, (, )) [Note that the backslash is a meta-character as well]")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
library(tidyverse)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F)
str(elon_tweets_df)
elon_tweets_df <- elon_tweets_df %>% arrange(desc(favoriteCount))
elon_tweets_df$text[1:5]
tags <- "#|@\\w+"
grep(pattern = tags, x = elon_tweets_df$text)
grep(tags, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = tags, replacement = "", elon_tweets_df$text)
iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub="") %>% head()
elon_tweets_df$text <- iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub = "")
url <- "http[s]?://[[:alnum:].\\/]+"
grep(url, elon_tweets_df$text, value = TRUE) %>% head()
grepl(url, elon_tweets_df$text) %>% head()
elon_urls <- elon_tweets_df %>% filter(grepl(url, elon_tweets_df$text))
elon_tweets_df$text <- gsub(pattern = "http[s]?://[[:alnum:].\\/]+", replacement = "", elon_tweets_df$text)
trail <- "[ ]+$|[0-9]*|[[:punct:]]"
grep(trail, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = trail, replacement = "", elon_tweets_df$text)
elon_tweets_df$text[1:5]
elon_tweets_df$text <- gsub(pattern = space, replacement = " ", elon_tweets_df$text)
elon_tweets_df$text[1:5]
extra <- "^[ ]"
grep(extra, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = extra, replacement = " ", elon_tweets_df$text)
elon_tweets_df$text[1:5]
extra <- "^[ ]"
grep(extra, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = extra, replacement = "", elon_tweets_df$text)
elon_tweets_df$text[1:5]
strsplit(elon_tweets_df$text, " ")
str(strsplit(elon_tweets_df$text, split = " "))
unlist(strsplit(elon_tweets_df$text, split = " "))
str(unlist(strsplit(elon_tweets_df$text, split = " ")))
unlist(strsplit(elon_tweets_df$text, split = " "))
words <- unlist(strsplit(elon_tweets_df$text, split = " "))
strsplit(words, "\\n")
unlist(strsplit(words, "\\n"))
gsub(words, "[[:lower:]]")
gsub(words, "[[:lower:]]", words)
words <- tolower(unlist(strsplit(words, "\\n")))
words
words <- casefold(unlist(strsplit(words, "\\n")), upper = TRUE)
words <- casefold(unlist(strsplit(words, "\\n")), upper = FALSE)
head(words)
words[1:50]
tail(words)
tail(words)
tail(words, 50)
words <- tolower(unlist(strsplit(words, "\\")))
words <- tolower(unlist(strsplit(words, "\\\")))
words <- tolower(unlist(strsplit(words, "\\\\")))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "\\")))
words <- tolower(unlist(strsplit(words, "[\\]")))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "[\\\\]")))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "[\\\\]", fixed = FALSE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "[\\]", fixed = FALSE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "[\]", fixed = FALSE)))
words <- tolower(unlist(strsplit(words, "\\", fixed = FALSE)))
words <- tolower(unlist(strsplit(words, "\\\\", fixed = FALSE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "\\\\", fixed = TRUE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "\\\\", fixed = TRUE, perl = TRUE)))
words <- tolower(unlist(strsplit(words, "\\\\",  perl = TRUE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "[\\\\]",  perl = TRUE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "[\\\\]|[^[:print:]]", fixed = FALSE)))
tail(words, 50)
words <- tolower(unlist(strsplit(words, "\\n|\\t")))
tail(words, 50)
library(knitr)
library(kableExtra)
text_table <- data.frame(
Expression = c("^", "$", "\\b", "\\B"),
Meaning = c("start of string", "end of string", "empty string at either edge of a word", "empty string that is NOT at the edge of a word")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("?", "*","+", "{n}", "{n,}", "{,n}", "{n,m}"),
Meaning = c("0 or 1", "0 or more", "1 or more", "exactly n", "at least n", "at most n", "between n and m (inclusive)")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("\\w, [A-z0-9], [[:alnum:]]", "\\d, [0-9], [[:digit:]]", "[A-z], [:alpha:]", "\\s, [[:space:]]", "[[:punct:]]", "[[:lower:]]", "[[:upper:]]", "\\W, [^A-z0-9]", "\\S", "\\D, [^0-9]"),
Meaning = c("word characters (letters + digits)", "digits", "alphabetical characters", "space", "punctuation", "lowercase", "uppercase", "not word characters", "not space", "not digits")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("|", ".", "[  ]", "[ - ]", "[^ ]", "( )"),
Meaning = c("or", "matches any single character", "matches ANY of the characters inside the brackets", "matches a RANGE of characters inside the brackets", "matches any character EXCEPT those inside the bracket", "grouping - used for _backreferencing_")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
text_table <- data.frame(
Expression = c("\\"),
Meaning = c("escape! necessary to use special meta-characters (*, $, ^, ., ?, |, \\, [, ], {, }, (, )) [Note that the backslash is a meta-character as well]")
)
kable(text_table, "html") %>%
kable_styling(full_width = F) %>%
column_spec(1, italic = T, border_right = T) %>%
column_spec(2, width = "40em")
library(tidyverse)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F)
str(elon_tweets_df)
elon_tweets_df <- elon_tweets_df %>% arrange(desc(favoriteCount))
elon_tweets_df$text[1:5]
tags <- "#|@\\w+"
grep(pattern = tags, x = elon_tweets_df$text)
grep(tags, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = tags, replacement = "", elon_tweets_df$text)
iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub="") %>% head()
elon_tweets_df$text <- iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub = "")
url <- "http[s]?://[[:alnum:].\\/]+"
grep(url, elon_tweets_df$text, value = TRUE) %>% head()
grepl(url, elon_tweets_df$text) %>% head()
elon_urls <- elon_tweets_df %>% filter(grepl(url, elon_tweets_df$text))
elon_tweets_df$text <- gsub(pattern = "http[s]?://[[:alnum:].\\/]+", replacement = "", elon_tweets_df$text)
trail <- "[ ]+$|[0-9]*|[[:punct:]]"
grep(trail, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = trail, replacement = "", elon_tweets_df$text)
elon_tweets_df$text[1:5]
space <- "\\s{2,}"
grep(space, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = space, replacement = " ", elon_tweets_df$text)
elon_tweets_df$text[1:5]
extra <- "^[ ]"
grep(extra, elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <- gsub(pattern = extra, replacement = "", elon_tweets_df$text)
elon_tweets_df$text[1:5]
strsplit(elon_tweets_df$text, split = " ")
str(strsplit(elon_tweets_df$text, split = " "))
words <- tolower(unlist(strsplit(words, "\\n|\\t")))
tail(words, 50)
tail(words, 50)
words[1:50]
tail(words, 50)
count(words)
count(as.factor(words))
n_groups(words)
n_groups(data.frame(words))
n_groups(data.frame(factor(words)))
test <- data.frame(words) %>% select(words) %>% count(factor(words)) %>% arrange(desc(n))
data.frame(words)
test <- data.frame(words) %>% count(factor(.)) %>% arrange(desc(n))
test <- data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
library(tidytext)
stop <- stop_words
View(stop)
str(stop)
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea"),
lexicon = "custom")
stop <- bind_rows(stop, add_stop)
stop <- stop_words
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea"),
lexicon = "custom")
stop <- bind_rows(stop, add_stop)
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea"),
lexicon = "custom", stringsAsFactors = FALSE)
stop <- bind_rows(stop, add_stop)
stop <- stop_words
stop <- bind_rows(stop, add_stop)
anti_join(words, stop, by=c("factor(value)" = "word"))
anti_join(data.frame(words), stop, by=c("factor(value)" = "word"))
anti_join(data.frame(words), stop, by=c("factor(words)" = "word"))
str(data.frame(words)
)
anti_join(data.frame(words), stop, by=c("words" = "word"))
words <- anti_join(data.frame(words), stop, by=c("words" = "word"))
words %>% count(words) %>% arrange(desc(n))
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea", "relnofollowtwitter"),
lexicon = "custom", stringsAsFactors = FALSE)
stop <- bind_rows(stop, add_stop)
stop <- stop_words
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea", "relnofollowtwitter"),
lexicon = "custom", stringsAsFactors = FALSE)
stop <- bind_rows(stop, add_stop)
words <- anti_join(data.frame(words), stop, by=c("words" = "word"))
words %>% count(words) %>% arrange(desc(n))
stop <- stop_words
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea", "relnofollowtwitter", "relnofollowinstagrama"),
lexicon = "custom", stringsAsFactors = FALSE)
stop <- bind_rows(stop, add_stop)
words <- anti_join(data.frame(words), stop, by=c("words" = "word"))
words %>% count(words) %>% arrange(desc(n))
nrc <- sentiments %>%
filter(lexicon == "nrc") %>%
dplyr::select(word, sentiment)
nrc
by_source_sentiment <- trump_words %>%
inner_join(nrc, by =c("factor(value)" = "word")) %>%
count(sentiment) %>%
arrange(desc(nn))
by_source_sentiment <- words %>%
inner_join(nrc, by =c("factor(value)" = "word")) %>%
count(sentiment) %>%
arrange(desc(nn))
by_source_sentiment <- words %>%
inner_join(nrc, by =c("words" = "word")) %>%
count(sentiment) %>%
arrange(desc(nn))
by_source_sentiment <- words %>%
inner_join(nrc, by =c("words" = "word")) %>%
count(sentiment) %>%
arrange(desc(n))
head(by_source_sentiment)
library("wordcloud")
library("viridis")
words %>%
top_n(50) %>%
with(wordcloud(word, n, ordered.colors = TRUE, colors = viridis(61), use.r.layout = TRUE))
length(words %>% top_n(50))
words <- words %>% count(words) %>% arrange(desc(n))
words %>%
top_n(50) %>%
with(wordcloud(word, n, ordered.colors = TRUE, colors = viridis(61), use.r.layout = TRUE))
length(words %>% top_n(50))
words %>%
top_n(50) %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(61), use.r.layout = TRUE))
words %>%
with(wordcloud(words[1:50,], n, ordered.colors = TRUE, colors = viridis(61), use.r.layout = TRUE))
words[1:50,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(61), use.r.layout = TRUE))
str(words[1:50,])
words[1:50,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(50), use.r.layout = TRUE))
words[2:50,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(50), use.r.layout = TRUE))
words[2:50,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(49), use.r.layout = TRUE))
words[1:50,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(50), use.r.layout = TRUE))
trump_tweets_df <- read.delim("data/trump_tweets_df.txt", sep = "\t")
trump_tweets_df <- trump_tweets_df %>% arrange(desc(favoriteCount))
trump_tweets_df$text[1:5]
str_detect(trump_tweets_df$text, tags)
str_locate(trump_tweets_df$text, tags)
str_extract(trump_tweets_df$text, tags)
str_extract(trump_tweets_df$text, tags)
str_extract_all(string = trump_tweets_df$text, pattern = tags)
str_extract(string = trump_tweets_df$text, pattern = tags)
str_detect(trump_tweets_df$text, tags)
str_detect(trump_tweets_df$text, tags)
save <- str_extract_all(trump_tweets_df$text, "[#|@|[:alnum:]]+([^\\s][[:alnum:]]+)?", simplify = TRUE)
View(save)
trump_tweets_df$text[1]
trump_tweets_df$text[2]
url
tags
clean <- "http[s]?://[[:alnum:].\\/]+|#|@\\w+|[0-9]*|\\n|\\t"
clean <- "http[s]?://[[:alnum:].\\/]+|#|@\\w+|[0-9]*|\\n|\\t|[[:punct:]]"
str_remove(trump_tweets_df$text, clean, "")
str_remove(trump_tweets_df$text, pattern = clean, replacement = "")
str_remove(trump_tweets_df$text, pattern = clean)
clean <- "(http[s]?://[[:alnum:].\\/]+)|(#|@\\w+)|([0-9]*)|\\n|\\t|[[:punct:]]"
str_remove(trump_tweets_df$text[1:5], pattern = clean)
clean <- "[[[punct:]]"
rm(nrc)
rm(save)
clean <- "[[punct:]]"
str_remove(trump_tweets_df$text[1:5], pattern = clean)
clean <- "[[:punct:]]"
str_remove(trump_tweets_df$text[1:5], pattern = clean)
str_remove(trump_tweets_df$text[1:5], pattern = urls)
str_remove(trump_tweets_df$text[1:5], pattern = url)
url
rm(ls())
rm(ls)
rm(list = ls())
str(knitr::opts_chunk$get())
library("tidyverse")
library("tidytext")
library("viridis")
library("knitr")
library("kableExtra")
library("wordcloud")
tags <- "#|@\\w+"
url <- "http[s]?://[[:alnum:].\\/]+"
trail <- "[ ]+$|[0-9]*|[[:punct:]]"
space <- "\\s{2,}"
extra <- "^[ ]"
stop <- stop_words
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea", "relnofollowtwitter", "relnofollowinstagrama"),
lexicon = "custom", stringsAsFactors = FALSE)
stop <- bind_rows(stop, add_stop)
trump_tweets_df <- read.delim("data/trump_tweets_df.txt", sep = "\t")
trump_tweets_df <- trump_tweets_df %>% select(text, favoriteCount) %>% arrange(desc(favoriteCount))
trump_tweets_df$text <- iconv(trump_tweets_df$text, "UTF-8", "ASCII", sub = "")
trump_tweets_df$text <- str_replace_all(trump_tweets_df$text, pattern = url, replacement = "")
clean[1:10]
clean <- str_remove_all(trump_tweets_df$text, pattern = tags)
clean[1:10]
trump_tweets_df$text[1:20]
View(trump_tweets_df)
clean[171]
clean3 <- "\\$?[0-9]*%?"
str_remove_all(clean[1:10], pattern = clean3)
clean[1:20]
clean5 <- "[[:punct:]]"
str_remove_all(clean[1:10], pattern = clean5)
clean[1:20]
clean <- str_remove_all(clean, pattern = clean5)
clean[1:20]
clean <- str_remove_all(trump_tweets_df$text, pattern = tags)
clean6 <- "\\$?[0-9]*%?|[[:punct:]]"
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "\\$?[0-9]*%?[[:punct:]]"
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
tail(clean)
tail(clean)[1:20]
tail(trump_tweets_df$text)[1:20]
trump_tweets_df <- read.delim("data/trump_tweets_df.txt", sep = "\t")
trump_tweets_df <- trump_tweets_df %>% select(text, favoriteCount) %>% arrange(desc(favoriteCount))
tail(trump_tweets_df$text)[1:20]
clean <- str_remove_all(trump_tweets_df$text)
clean <- trump_tweets_df$text
clean6 <- "#|@?\\w+\\$?[0-9]*%?[[:punct:]]"
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
trump_tweets_df$text <- str_replace_all(trump_tweets_df$text, pattern = url, replacement = "")
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "[#|@\\w+]?\\$?[0-9]*%?[[:punct:]]"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "[#|@]?\\$?[0-9]*%?[[:punct:]]"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "[#|@]\\$?[0-9]*%?[[:punct:]]"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "[#?|@?]\\$?[0-9]*%?[[:punct:]]"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "#?@?\\$?[0-9]*%?[[:punct:]]"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "\\$?[0-9]*%?[[:punct:]]#?@?"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "#.@.\\$?[0-9]*%?[[:punct:]]"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "#.\\@.\\$?[0-9]*%?[[:punct:]]"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "\\#.\\@.\\$?[0-9]*%?[[:punct:]]"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "\\$?[0-9#@]*%?[[:punct:]]"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "\\$?[0-9]*%?[[:punct:]]"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "\\$?[0-9]*%?[[:punct:]]"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "\\$?[0-9]*%?"
clean <- trump_tweets_df$text
clean <- str_remove_all(trump_tweets_df$text, pattern = clean)
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "\\$?[0-9]*%?[[:punct:]]"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean6 <- "\\$?[0-9]*%?[[:punct:]]?"
clean <- trump_tweets_df$text
clean <- str_remove_all(clean, pattern = clean6)
clean[1:20]
clean[171]
clean2 <- "#|@\\w+"
str_remove_all(clean[1:10], pattern = clean2)
str_detect(clean[1:10], pattern = tags)
str_detect(clean, pattern = tags)
clean_all <- "\\$?[0-9]*%?[[:punct:]]?"
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean_all)
trump_tweets_df$text[1:20]
trump_tweets_df <- read.delim("data/trump_tweets_df.txt", sep = "\t")
trump_tweets_df <- trump_tweets_df %>% select(text, favoriteCount) %>% arrange(desc(favoriteCount))
trump_tweets_df$text <- iconv(trump_tweets_df$text, "UTF-8", "ASCII", sub = "")
trump_tweets_df$text <- str_replace_all(trump_tweets_df$text, pattern = url, replacement = "")
clean_all <- "[0-9]*?[[:punct:]]?"
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean_all)
trump_tweets_df$text[1:20]
clean_all <- "[0-9]?[[:punct:]]?"
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean_all)
trump_tweets_df$text[1:20]
trump_tweets_df <- read.delim("data/trump_tweets_df.txt", sep = "\t")
trump_tweets_df <- trump_tweets_df %>% select(text, favoriteCount) %>% arrange(desc(favoriteCount))
trump_tweets_df$text <- iconv(trump_tweets_df$text, "UTF-8", "ASCII", sub = "")
trump_tweets_df$text <- str_replace_all(trump_tweets_df$text, pattern = url, replacement = "")
trump_tweets_df$text[1:20]
trump_tweets_df$text[8] <- str_replace(trump_tweets_df$text[8], "14", "22")
trump_tweets_df$text[1:20]
clean_all <- "[0-9]?[[:punct:]]?"
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean_all)
trump_tweets_df$text[1:20]
clean_all <- "[0-9]?[[:punct:]]?"
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean_all)
trump_tweets_df$text[1:20]
trump_tweets_df$text <- str_trim(trump_tweets_df$text, side = "both")
trump_tweets_df$text[1:10]
trump_tweets_df$text <- str_squish(trump_tweets_df$text)
trump_tweets_df$text[1:10]
trump_tweets_df$text <- tolower(trump_tweets_df$text)
trump_tweets_df$text[1:10]
words <- unlist(str_split(trump_tweets_df$text, pattern = " ", simplify = FALSE))
words <- anti_join(data.frame(words), stop, by=c("words" = "word"))
words %>% count(words) %>% arrange(desc(n))
words <- words %>% count(words) %>% arrange(desc(n))
words %>% count(words) %>% arrange(desc(n))
words
words
add_stop <- data.frame(word = c("rel=nofollow>twitter", "href=", "iphone<a>", "<a","dont", "$", "href=downloadipad", "ipad<a>" ),
lexicon = "custom", stringsAsFactors = FALSE)
stop <- bind_rows(stop, add_stop)
words <- anti_join(data.frame(words), stop, by=c("words" = "word"))
words %>% count(words) %>% arrange(desc(n))
words
words[2:51,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, c(3,.5),colors = viridis(50), use.r.layout = TRUE))
tail(words)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", fill=TRUE, stringsAsFactors = F)
View(trump_tweets_df)
View(elon_tweets_df)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F)
View(elon_tweets_df)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F, quote="", fill = FALSE)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F, quote="", fill = FALSE, na.strings = ".")
elon_tweets_df <- read.table("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F, quote="", fill = FALSE, na.strings = ".", comment.char = "#")
View(elon_tweets_df)
elon_tweets_df <- read.table("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F, quote="", fill = FALSE, na.strings = ".", comment.char = "#", allowEscapes = TRUE)
elon_tweets_df <- read.table("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F, quote="", fill = TRUE, na.strings = ".", comment.char = "#", allowEscapes = TRUE)
View(elon_tweets_df)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F, quote="", fill = TRUE, na.strings = ".", comment.char = "#", allowEscapes = TRUE)
View(elon_tweets_df)
View(elon_tweets_df)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", header = TRUE, stringsAsFactors = F, quote="", fill = TRUE, na.strings = ".", comment.char = "#", allowEscapes = TRUE)
View(elon_tweets_df)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", header = TRUE, stringsAsFactors = F, quote="", fill = FALSE, na.strings = ".", comment.char = "#", allowEscapes = TRUE)
View(elon_tweets_df)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", header = TRUE, stringsAsFactors = F,fill = FALSE)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F,fill = FALSE)
View(elon_tweets_df)
elon_tweets_df$text[22]
View(elon_tweets_df)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F,fill = FALSE, quote="")
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F,fill = FALSE, quote="", encoding = "ASCII")
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F,fill = TRUE, quote="", encoding = "ASCII")
View(elon_tweets_df)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F,fill = TRUE, allowEscapes = TRUE, quote="", encoding = "ASCII")
View(elon_tweets_df)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F,fill = TRUE, allowEscapes = TRUE, quote="", encoding = "UTF-8")
View(elon_tweets_df)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F,fill = TRUE, allowEscapes = TRUE, encoding = "UTF-8")
View(elon_tweets_df)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F,fill = TRUE, allowEscapes = TRUE, encoding = "UTF-8", colClasses = c("character"), as.is = T, **quote = ""**)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F,fill = TRUE, allowEscapes = TRUE, encoding = "UTF-8", colClasses = c("character"), as.is = T, quote = "")
View(elon_tweets_df)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F, allowEscapes = TRUE, encoding = "UTF-8", as.is = T)
View(elon_tweets_df)
elon_tweets_df$text
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F, allowEscapes = TRUE)
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F, allowEscapes = TRUE)
View(elon_tweets_df)
View(elon_tweets_df)
