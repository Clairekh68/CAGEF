library(png)
install.packages('png"
)
install.packages("png")
library(png)
a <- readPNG(filename = "img/turtle_challenge.jpg", width = 100)
install.packages('jpeg')
library(jpeg)
a <- readJPEG("img/turtle_challenge.jpg")
```{r results='asis'}
library(xtable)
df <- data.frame(cbind(c("2", "10", "9","0"), c("4, 12, 12, 1"), c("6", "3", "0","0"), c("8","6", "1", "1")))
df
df <- data.frame(cbind(c("2", "10", "9","0"), c("4", "12", "12", "1"), c("6", "3", "0","0"), c("8","6", "1", "1")))
df
ibrary(xtable)
library(xtable)
options(xtable.comment = FALSE)
df <- data.frame(cbind(c("2", "10", "9","0"), c("4", "12", "12", "1"), c("6", "3", "0","0"), c("8","6", "1", "1")))
print(xtable(df),type="latex", hline.after = NULL, sanitize.text.function=function(x){x})
4
4+
4+
q
q()
library(RColorBrewer)
palette1 <- brewer.pal(12, "Paired")
palette2 <- brewer.pal(12, "Set3")
custom <- c(palette1, palette2)
unique(custom)
is.unique(custom)
all.unique(custom)
length(unique(custom))
data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
library(tidyverse)
data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
library("tidyverse")
library("tidytext")
library("viridis")
library("knitr")
library("kableExtra")
library("wordcloud")
elon_tweets_df <- read.delim("elon_tweets_df.txt", sep = "\t", stringsAsFactors = F)
setwd("~/Git/CAGEF/Lesson_4/data")
elon_tweets_df <- read.delim("elon_tweets_df.txt", sep = "\t", stringsAsFactors = F)
elon_tweets_df <- elon_tweets_df %>%
select(text, favoriteCount) %>%
arrange(desc(favoriteCount))
tags <- "#|@\\w+"
grep(pattern = tags, x = elon_tweets_df$text, value = TRUE) %>% head()
elon_tweets_df$text <-gsub(pattern = tags, replacement = "", elon_tweets_df$text)
elon_tweets_df$text <- iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub = "")
trail <- "[ ]+$|[0-9]*|[[:punct:]]"
elon_tweets_df$text <-gsub(pattern = trail, replacement = "", elon_tweets_df$text)
space <- "\\s{2,}"
elon_tweets_df$text <-gsub(pattern = space, replacement = " ", elon_tweets_df$text)
extra <- "^[ ]"
elon_tweets_df$text <- gsub(pattern = extra, replacement = "", elon_tweets_df$text)
words <- unlist(strsplit(elon_tweets_df$text, split = " "))
words <- unlist(strsplit(words, split = "\t|\n"))
words <- unlist(strsplit(words, split = " "))
words <- tolower(words)
head(words, 50)
data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
stop_words <- stop_words
str(stop_words)
View(stop_words)
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea", "relnofollowtwitter", "relnofollowinstagrama"), lexicon = "custom", stringsAsFactors = F)
stop_words <- bind_rows(stop_words, add_stop)
tail(stop_words)
str(data.frame(words))
words <- anti_join(data.frame(words), stop_words, by = c("words" = "word")
data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
words <- anti_join(data.frame(words), stop_words, by = c("words" = "word"))
data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea", "relnofollowtwitter", "relnofollowinstagrama", "hrefhttptwittercomdownloadiphone"), lexicon = "custom", stringsAsFactors = F)
stop_words <- bind_rows(stop_words, add_stop)
words <- anti_join(data.frame(words), stop_words, by = c("words" = "word"))
data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
data.frame(words) %>% count(factor(words)) %>% arrange(desc(n)) %>% head(50)
words <- data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
head(words, 50)
View(words)
words[2:51,] %>% with(wordcloud(words, n, ordered.colors = TRUE, color = viridis(50), use.r.layout = TRUE))
words[2:51,] %>% with(wordcloud(., n, ordered.colors = TRUE, color = viridis(50), use.r.layout = TRUE))
length(words[2:51,])
str(words)
dim(words[2:51,])
words[2:51,] %>% with(wordcloud(factor(words), n, ordered.colors = TRUE, color = viridis(50), use.r.layout = TRUE))
str(knitr::opts_chunk$get())
elon_tweets_df <- read.delim("data/elon_tweets_df.txt", sep = "\t", stringsAsFactors = F)
elon_tweets_df <- elon_tweets_df %>%
select(text, favoriteCount) %>%
arrange(desc(favoriteCount))
tags <- "#|@\\w+"
elon_tweets_df$text <- gsub(pattern = tags, replacement = "", elon_tweets_df$text)
elon_tweets_df$text <- iconv(elon_tweets_df$text, "UTF-8", "ASCII", sub = "")
url <- "http[s]?://[[:alnum:].\\/]+"
elon_tweets_df$text <- gsub(pattern = "http[s]?://[[:alnum:].\\/]+", replacement = "", elon_tweets_df$text)
trail <- "[ ]+$|[0-9]*|[[:punct:]]"
elon_tweets_df$text <- gsub(pattern = trail, replacement = "", elon_tweets_df$text)
space <- "\\s{2,}"
elon_tweets_df$text <- gsub(pattern = space, replacement = " ", elon_tweets_df$text)
extra <- "^[ ]"
elon_tweets_df$text <- gsub(pattern = extra, replacement = "", elon_tweets_df$text)
words <- unlist(strsplit(elon_tweets_df$text, split = " "))
words <- tolower(unlist(strsplit(words, "\\n|\\t")))
stop_words <- stop_words
add_stop <- data.frame(word = c("na", "false", "href", "rel", "nofollow", "true", "amp", "twitter", "iphonea", "relnofollowtwitter", "relnofollowinstagrama"),
lexicon = "custom", stringsAsFactors = FALSE)
stop_words <- bind_rows(stop_words, add_stop)
words <- anti_join(data.frame(words), stop_words, by=c("words" = "word"))
words <- words %>% count(words) %>% arrange(desc(n))
words[2:51,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, colors = viridis(50), use.r.layout = TRUE))
trump_tweets_df <- read.delim("trump_tweets_df.txt", sep = "\t", stringsAsFactors = F)
trump_tweets_df$text <- iconv(trump_tweets_df$text, "UTF-8", "ASCII", sub = "")
trump_tweets_df <- trump_tweets_df %>% select(text, favoriteCount), %>% arrange(desc(favoriteCount))
trump_tweets_df <- trump_tweets_df %>% select(text, favoriteCount) %>% arrange(desc(favoriteCount))
trump_tweets_df[1:5,]
trump_tweets_df[1:5]
trump_tweets_df$text[1:5]
str_extract(string = trump_tweets_df$text, pattern = tags) %>% head(100)
str_detect(string = trump_tweets_df$text, pattern = tags) %>% head(100)
str_replace_all(string = trump_tweets_df$text, pattern = url, replacement = "") %>% head(100)
trump_tweets_df$text <- str_replace_all(string = trump_tweets_df$text, pattern = url, replacement = "")
clean <- "[0-9]?[[:punct:]]?
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean)
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean)
trump_tweets_df$text[1:100]
clean <- "[0-9]?[[:punct:]]?"
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean)
trump_tweets_df$text[1:100]
clean <- "[[0-9]*[[:punct:]]*]"
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean)
trump_tweets_df$text[1:100]
clean <- "[[0-9]*[[:punct:]]*\\$*]"
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean)
trump_tweets_df$text[1:100]
trump_tweets_df <- read.delim("trump_tweets_df.txt", sep = "\t", stringsAsFactors = F)
trump_tweets_df$text <- iconv(trump_tweets_df$text, "UTF-8", "ASCII", sub = "")
trump_tweets_df <- trump_tweets_df %>% select(text, favoriteCount) %>% arrange(desc(favoriteCount))
trump_tweets_df$text <- str_replace_all(string = trump_tweets_df$text, pattern = url, replacement = "")
clean <- "[[0-9]*[[:punct:]]*\\$*]"
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean)
trump_tweets_df$text[1:100]
trump_tweets_df <- read.delim("trump_tweets_df.txt", sep = "\t", stringsAsFactors = F)
trump_tweets_df$text <- iconv(trump_tweets_df$text, "UTF-8", "ASCII", sub = "")
trump_tweets_df <- trump_tweets_df %>% select(text, favoriteCount) %>% arrange(desc(favoriteCount))
trump_tweets_df$text <- str_replace_all(string = trump_tweets_df$text, pattern = url, replacement = "")
clean <- "[[0-9][[:punct:]]\\$]*"
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean)
trump_tweets_df$text[1:100]
trump_tweets_df <- read.delim("trump_tweets_df.txt", sep = "\t", stringsAsFactors = F)
trump_tweets_df$text <- iconv(trump_tweets_df$text, "UTF-8", "ASCII", sub = "")
trump_tweets_df <- trump_tweets_df %>% select(text, favoriteCount) %>% arrange(desc(favoriteCount))
trump_tweets_df$text <- str_replace_all(string = trump_tweets_df$text, pattern = url, replacement = "")
clean <- "[[0-9][[:punct:]]\\$]"
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean)
trump_tweets_df$text[1:100]
trump_tweets_df$text <- str_trim(trump_tweets_df$text, side= "both")
trump_tweets_df$text[1:100]
trump_tweets_df$text <- str_squish(trump_tweets_df$text)
trump_tweets_df$text[1:100]
words <- unlist(str_split(trump_tweets_df$text, pattern = " ", simplify = FALSE))
words <- tolower(words)
words <- anti_join(data.frame(words), stop_words, by = c("words" = "word"))
words <- data.frame(words) %>% count(factor(words)) %>% arrange(desc(n))
head(words, 50)
add_stop <- data.frame(word = c("rel=nofollow>twitter", "href=", "iphone<a>", "<a", "dont", "ipad<a>", "href=downloadipad"), lexicon = "custom", stringsAsFactors = F)
stop_words <- bind_rows(stop_words, add_stop)
tail(stop_words)
words <- anti_join(data.frame(words), stop_words, by = c("words" = "word"))
words <- anti_join(words, stop_words, by = c("factor(words)" = "word"))
words
words[2:51,] %>% with(wordcloud(factor(words), n, ordered.colors = TRUE, color = viridis(50), use.r.layout = TRUE))
words[2:51,] %>% with(words, n, ordered.colors = TRUE, color = viridis(50), use.r.layout = TRUE))
words[2:51,] %>% with(words, n, ordered.colors = TRUE, color = viridis(50), use.r.layout = TRUE)
library(wordcloud)
words[2:51,] %>% with(words, n, ordered.colors = TRUE, color = viridis(50), use.r.layout = TRUE)
words[2:51,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, c(3,.5),colors = viridis(50), use.r.layout = TRUE))
trump_tweets_df <- read.delim("data/trump_tweets_df.txt", sep = "\t", stringsAsFactors = FALSE)
trump_tweets_df <- trump_tweets_df %>% select(text, favoriteCount) %>% arrange(desc(favoriteCount))
trump_tweets_df$text <- str_replace_all(trump_tweets_df$text, pattern = url, replacement = "")
clean_all <- "[[0-9][[:punct:]]\\$]"
trump_tweets_df$text <- str_remove_all(trump_tweets_df$text, pattern = clean_all)
trump_tweets_df$text <- str_trim(trump_tweets_df$text, side = "both")
trump_tweets_df$text <- str_squish(trump_tweets_df$text)
trump_tweets_df$text <- tolower(trump_tweets_df$text)
words <- unlist(str_split(trump_tweets_df$text, pattern = " ", simplify = FALSE))
str(words)
words <- anti_join(data.frame(words), stop_words, by=c("words" = "word"))
words <- words %>% count(words) %>% arrange(desc(n))
add_stop <- data.frame(word = c("rel=nofollow>twitter", "href=", "iphone<a>", "<a","dont", "$", "href=downloadipad", "ipad<a>" ),
lexicon = "custom", stringsAsFactors = FALSE)
stop_words <- bind_rows(stop_words, add_stop)
words <- anti_join(data.frame(words), stop_words, by=c("words" = "word"))
words[1:50,]
words[2:51,] %>%
with(wordcloud(words, n, ordered.colors = TRUE, c(3,.5),colors = viridis(50), use.r.layout = TRUE))
setwd("~/")
str(knitr::opts_chunk$get())
str(knitr::opts_chunk$get())
library(rmarkdown)
knitr::opts_chunk$set(echo = TRUE)
plot(cars$speed, cars$distance)
plot(cars$speed, cars$dist)
knitr::opts_chunk$set(echo = TRUE)
str(summary(cars))
data <- data.frame(speed = summary(cars)[,1], distance = summary(cars)[,2])
kable(dat)
library(kable)
kable(dat)
library(kableExtra)
kable(dat)
setwd("~/Git/CAGEF/Lesson_5/data")
cholesterol <- read.delim("SISG-Data-cholesterol.txt", sep = " ", header = TRUE)
str(cholesterol)
View(cholesterol)
library(tidyverse)
library(limma)
library(gee)
library(multicomp)
library(multcomp)
library(broom)
ggplot(cholesterol, aes(age, chol)) +
geom_point()
ggplot(cholesterol, aes(age, chol)) +
geom_point() +
geom_hline(yintercept = mean(cholesterol$chol), color = "red")
cholesterol <- cholesterol %>% mutate(age_group = ifelse(test = cholesterol$age > 55, yes = 1, no = 0))
str(cholesterol)
ggplot(cholesterol, aes(factor(age_group), chol)) +
scale_x_discrete(labels = c("30-55", "56-80") +
ylab("cholesterol (mg/dl)")
ggplot(cholesterol, aes(factor(age_group), chol)) +
geom_boxplot() +
scale_x_discrete(labels = c("30-55", "56-80")) +
xlab("age") +
ylab("cholesterol (mg/dl)")
t.test(x=cholesterol$age_group, y = cholesterol$chol, alternative = "two.sided", conf.level = 0.95, var.equal = TRUE)
t.test(cholesterol$chol ~ cholesterol$age_group, alternative = "two.sided", conf.level = 0.95, var.equal = TRUE)
ggplot(cholesterol, aes(age, chol)) +
geom_point() +
stat_smooth(method = "lm")
lm(chol ~ age, data = cholesterol)
fit <- lm(chol ~ age, data = cholesterol)
summary(fit)
confint(fit)
ggplot(cholesterol, aes(BMI, chol))+
geom_point() +
stat_smooth(method = "lm")
ggplot(cholesterol, aes(age, BMI))+
geom_point() +
stat_smooth(method = "lm")
mfit <- lm(chol ~ age  + BMI, cholesterol)
summary(mfit)
anova(fit, mfit)
bfit <- lm(chol~age*BMI, cholesterol)
summary(bfit)
anova(fit, bfit)
anova(mfit, bfit)
lfit <- lm(chol~age + BMI + age:BMI, cholesterol)
summary(lfit)
ggplot(cholesterol, aes(as.factor(rs174548), chol)) + geom_boxplot()
anfit1 <- lm(chol~as.factor(rs174548), cholesterol)
summary(anfit1)
anova(anfit1)
tfit <- lm(chol~1 + as.factor(rs174548), cholesterol)
M <-  contrMat(table(cholesterol$rs174548, type = "Tukey"))
M <-  contrMat(table(cholesterol$rs174548), type = "Tukey")
M
mc <- glht(tfit, linfct = M)
summary(mc, test = adjusted("none"))
tfit <- lm(chol~1 - as.factor(rs174548), cholesterol)
M <-  contrMat(table(cholesterol$rs174548), type = "Tukey")
M
mc <- glht(tfit, linfct = M)
summary(mc, test = adjusted("none"))
tfit <- lm(chol~as.factor(rs174548)-1, cholesterol)
M <-  contrMat(table(cholesterol$rs174548), type = "Tukey")
M
mc <- glht(tfit, linfct = M)
summary(mc, test = adjusted("none"))
summary(mc, test = adjusted("bonferroni"))
anfit2 <- lm(chol~as.factor(sex) + as.factor(rs174548), cholesterol)
summary(anfit2)
genfit <- lm(chol~as.factor(sex), cholesterol)
anova(genfit, anfit2)
intfit2 <- lm(chol~as.factor(sex) * as.factor(rs174548), cholesterol)
summary(intfit2)
anova(anfit2, intfit2)
ggplot(cholesterol, aes(as.factor(sex), chol)) + geom_boxplot()
mfit2 <- lm(chol~age+ as.factor(sex), cholesterol)
summary(mfit2)
intfit3 <- lm(chol~age*sex, cholesterol)
intfit3 <- lm(chol~age*sex, cholesterol)
summary(infit3)
summary(intfit3)
anova(mfit2, intfit2)
anova(fit, mfit2)
anova(genfit, mfit2)
ggplot(cholesterol, aes(age, chol, color = factor(sex)))+
geom_point()+
stat_smooth(method = "lm")
ggplot(cholesterol, aes(age, chol, color = factor(rs174548)))+
geom_point()+
stat_smooth(method = "lm")
mfit3 <- lm(chol~age+ as.factor(rs174548), cholesterol)
summary(mfit3)
intfit3 <- lm(chol*age+ as.factor(rs174548), cholesterol)
intfit3 <- lm(chol~age * as.factor(rs174548), cholesterol)
summary(intfit3)
anova(mfit3,intfit3)
predict.lm(fit, age = 47)
predict.lm(fit, data.frame(age = 47))
predict(mfit, newdata = data.frame(BMI = c(21,26,30), age = 60), interval = "prediction", se.fit = TRUE)
mfit3$residuals
ggplot(cholesterol, aes(x=age, y = fit[["residuals"]])) +
geom_point() +
geom_hline(yintercept = 0, color = "black")
datfit <- augment(fit)
ggplot(datafit, aes(x=.fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0, color = "black")
ggplot(datfit, aes(x=.fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0, color = "black")
ggplot(datfit, aes(x=chol, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0, color = "black")
ggplot(datfit, aes(x=age, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0, color = "black")
ggplot(datfit, aes(x=.fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0, color = "black")
anfit1 <- augment(anfit1)
ggplot(anfit1, aes(.fitted, .resid, color = as.factor(rs174548)) +
ggplot(anfit1, aes(.fitted, .resid, color = as.factor(rs174548))) +
geom_point() +
geom_hline(yintercept = 0, color = "black")
ggplot(anfit1, aes(.fitted, .resid, color = as.factor.rs174548)) +
geom_point() +
geom_hline(yintercept = 0, color = "black")
ggplot(anfit1, aes(.fitted, .resid, color = as.factor.rs174548.)) +
geom_point() +
geom_hline(yintercept = 0, color = "black")
ggplot(anfit1, aes(.fitted, .resid, color = as.factor.rs174548.)) +
geom_jitter() +
geom_hline(yintercept = 0, color = "black")
bartlett.test(chol~factor(sex), data = cholestero