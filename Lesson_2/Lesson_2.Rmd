---
title: "Lesson 2 - Intro to Tidy Data: How to Filter, Subset, Transform and Merge your Data"
output: 
  html_document:
          keep_md: yes
          toc: TRUE
          toc_depth: 3
  html_notebook:
          toc: TRUE
          toc_depth: 3
---
***

![](img/magic.png){width=400px} 

</br>

##A quick intro to the intro to R Lesson Series

</br>

This 'Intro to R Lesson Series' is brought to you by the Centre for the Analysis of Genome Evolution & Function's (CAGEF) bioinformatics training initiative. This course was developed based on feedback on the needs and interests of the Department of Cell & Systems Biology and the Department of Ecology and Evolutionary Biology. 



This lesson is the second in a 6-part series. The idea is that at the end of the series, you will be able to import and manipulate your data, make exploratory plots, perform some basic statistical tests, test a regression model, and make some even prettier plots and documents to share your results. 


![](img/data-science-explore.png)

</br>

How do we get there? Today we are going to be learning about how to subset and filter our data and perform all of the manipulations one has to do in daily coding life. We will learn about tidy data and how it makes data analysis less of a pain. We will perform some basic statistics on our newly transformed dataset. Next week we will learn how to tidy our data, subset and merge data and generate descriptive statistics. The next lesson will be data cleaning and string manipulation; this is really the battleground of coding - getting your data into the format where you can analyse it. After that, we will make all sorts of plots - from simple data exploration to interactive plots - this is always a fun lesson. And then lastly, we will learn to write some functions, which really can save you time and help scale up your analyses.


![](img/spotify-howtobuildmvp.gif)

</br>

The structure of the class is a code-along style. It is hands on. The lecture AND code we are going through are available on GitHub for download at https://github.com/eacton/CAGEF __(Note: repo is private until approved)__, so you can spend the time coding and not taking notes. As we go along, there will be some challenge questions and multiple choice questions on Socrative. At the end of the class if you could please fill out a post-lesson survey (https://www.surveymonkey.com/r/....), it will help me further develop this course and would be greatly appreciated. 


***
__Objective:__ At the end of this session you will know the principles of tidy data, and be able to subset and transform your data, merge data frames, and perform simple calculations.

###Our Dataset

Metagenomic 16SrRNA sequencing of latrines from Tanzania and Vietnam at different depths (multiples of 20cm). 

We have 2 csv files (change one to tsv or xlsx - maybe both and make an additional files and get a google spreadsheet): 
1. A metadata file (Naming conventions: [Country_LatrineNo_Depth]) with sample names and environmental variables.
2. A table of species abundance.

B Torondel, JHJ Ensink, O Gunvirusdu, UZ Ijaz, J Parkhill, F Abdelahi, V-A Nguyen, S Sudgen, W Gibson, AW Walker, and C Quince.
Assessment of the influence of intrinsic environmental and geographical factors on the bacterial ecology of pit latrines
Microbial Biotechnology, 9(2):209-223, 2016. DOI:10.1111/1751-7915.12334

***

    In this lesson we want to answer 3 simple questions: 
    - Which latrine depth has the greatest mean number of OTUs?
    - Is there more Clostridia in Tanzania or Vietnam?
    - Which site had the greatest number of bacteria?


To help us be able to answer these questions, we are going to learn the main functions in the `dplyr()` and `tidyr()` packages. First, I am going to show you how to subset in __base R__ (ie. without a fancy package that makes your life easier). The reason that I am doing this is because while a lot of new packages play nicely with the functions we are going to use today, not all packages or data structures will work with these functions. However, the package functions will save so much time and typing that they are definitely worth learning.

Let's read in our dataset, store it in a variable, and remind ourselves about the structure.

```{r}

dat <- read.csv("data/SPE_pitlatrine.csv", stringsAsFactors = FALSE)
str(dat)

```

##A quick intro to base R subsetting

It is often extremely useful to subset your data by some logical condition (`==` (equal to), `|` (or)). For example, we may want to keep all rows that have either Fusobacteria or Methanobacteria.

```{r}

dat[dat$Taxa == "Fusobacteria" | dat$Taxa == "Methanobacteria", ]

```
Will this work?

```{r error = TRUE}

dat[dat$Taxa == "Fusobacteria" | "Methanobacteria", ]

```

What about this? 

```{r}
dat[dat$Taxa == c("Fusobacteria", "Methanobacteria"), ]
```

***

<div style="float:left;margin:0 10px 10px 0" markdown="1">
![](img/pause.jpg){width=100px}

</div>


##A quick reminder/warning about vectors. 

```{r}
c(1,2,3) + c(10,11)
c(1,2,3,4) + c(10,11)

```
Vectors recycle. In this case, R gave us a warning that our vectors don't match. However, R will assume that you know what you are doing as long as your one of your vector lengths is a multiple of your other vector length.

```{r}
c(1,2,3,4) + c(10,11)
```

In the above example, I am looking through the Taxa column for when Taxa is equal to Fusobacteria or Taxa is equal to Methanobacteria. However, with a vector, I am alternately going through all values of Taxa and asking: does the first value match Fusobacteria? does the second value match Methanobacteria? Then the vector recycles and asks: does the third value match Fusobacteria? does the 4th value match Methanobacteria? We end up with a data frame of zero observations when we are expecting a data frame of 2 observations. Be careful when filtering. You have been warned.

</br>

***
You can also filter to obtain more specific subsets using other logical operators (`&` (and), `!=` (does not equal)).

```{r}
dat[dat$Taxa == "Bacteroidia" & dat$T_2_1 != 0, ]
```

You can select columns by name or position, and reorder them as well (you can also do this for rows).

```{r}
dat[ , c("T_2_1", "Taxa")]
#equivalent to
dat[ , 2:1]

dat[ , "Taxa"]
#equivalent to
dat[ , -1]

```
You can arrange your data frame alphabetically or by value using `order()`.

```{r}
dat[order(dat$Taxa, decreasing = TRUE), ] 
```
You can order your data frame by multiple variables.

```{r}
dat[order(dat$T_2_1, decreasing = TRUE), ] 
dat[order(dat$T_2_1, dat$T_2_12, decreasing = TRUE), ] 
dat[order(dat$T_2_1, dat$T_2_12, dat$T_2_9, decreasing = TRUE), ]
```


***

The `dplyr` package, and some other common packages for data frame manipulation allow the use of the pipe function, `%>%`. This is equivalent to `|` for any unix peeps. This allows for a way of 'piping' the output of a function to the next function without making intermediate variables, which can save a ton of typing and environment clutter.

We are going to see how this works in conjunction with our first function, `filter()`. It is often extremely useful to subset your data by some logical condition (`==` (equal to), `|` (or)). In this case, we want to keep all rows that have either Fusobacteria or Methanobacteria.

```{r}
filter(dat, Taxa == "Fusobacteria" | Taxa == "Methanobacteria")
#equivalent to
dat %>% filter(Taxa == "Fusobacteria" | Taxa == "Methanobacteria")
#equivalent to
dat %>% filter(., Taxa == "Fusobacteria" | Taxa == "Methanobacteria")

```



You can also filter to obtain more specific subsets using other logical operators (`&` (and), `!=` (does not equal)).

```{r}
dat %>% filter(., Taxa == "Bacteroidia" & T_2_1 != 0)
```

You can subset columns by using the `select()` function. You can also reorder columns while using this function. I want to to compare the depth of latrine 2 at 9cm compared to 10cm, but I want Taxa in the last column.

```{r}

dat %>% select(T_2_9, T_2_10, Taxa)

```
If I wanted to perform a calculation, I would want to simply remove Taxa since it is of character type. If your data is unique you may want to retain your character data as rownames.

```{r}
rownames(dat) <- dat$Taxa
dat %>% select(-Taxa)

```
You can also select multiple columns at a time. For example, if we only wanted the samples from Vietnam, we could use "starts_with".

```{r}
dat %>% select(starts_with("V"))

```

Or all latrines with depths of 4 cm.

```{r}
dat %>% select(ends_with("4"))

```
You can look up other dplyr 'select_helpers' in the help menu.

The arrange() function helps you to sort your data. The default is ordered from smallest to largest (or a-z for character data). You can switch the order as shown below. 

I have added a few extra lines of code to show you how we can start building code that passes a result to the next function instead of creating a bunch of new variables to store data in between functions being exectuted. However, if you get more than 2 pipes `%>%` it gets hard to follow for a reader (or yourself after 5 minutes). Starting a new line after each pipe, allows a reader to easily see which function is operating and makes it easier to follow your logic.

```{r}
dat %>% select(Taxa, T_2_1) %>% arrange(desc(T_2_1)) %>% filter(T_2_1 !=0) %>% filter(Taxa != "Unknown") %>% unique()
#equivalent to
dat %>% 
  select(Taxa, T_2_1) %>% 
  arrange(desc(T_2_1)) %>% 
  filter(T_2_1 !=0) %>%
  filter(Taxa != "Unknown") %>%
  unique()
```

`mutate()` is a function to create new column, most often the product of a calculation. For example, let's calculate the total number of OTUs for each bacteria. You must specify a column name for the column you are creating. `transmute()' will also create a new variable, but it will drop the existing variables.

```{r}

dat %>% select(-Taxa) %>% mutate(total_OTUs = rowSums(.))

```
Versus:

```{r}
dat %>% select(-Taxa) %>% transmute(total_OTUs = rowSums(.))

```

dplyr has one more super-useful function, `summarize()`, but I'm going to wait until the data is in a better format to showcase it. Speaking of which...  

##Intro to tidy data

_Why tidy data?_

- Know the principles of tidy data and why it is useful to have your data in this format

Tidy data has:

1. Each variable forms a column.
2. Each observation forms a row.
3. Each type of observational unit forms a table.

This seems pretty straight forward, and it is. It is the datasets you get that will not be straight forward.

The 5 most common problems with messy datasets are:
- common headers are values, not variable names
- multiple variables in one column
- variables stored in both rows and columns
- a single variable stored in multiple tables 
- multiple types of observational units stored in the same table

Fortunately, Hadley has also given us the tools to solve these problems.

###Intro to the tidyverse

The tidyverse is the universe of packages created by Hadley Wickham for data analysis. There are packages to help import, tidy, transform, model and visualize data. His packages are pretty popular, so he made a package to load all of his packages at once. This wrapper package is tidyverse. In this lesson series we have used readr and readxl, and we will be using dplyr and tidyr today, and stringr and ggplot2 in future lessons. Install the package now.

```{r eval=FALSE}
install.packages("tidyverse")
```


![](img/tidyverse1.png)

Hadley has a large fan-base. Someone even made a plot of Hadley using ggplot2.


![](img/HadleyObama2.png)


Back to the normalverse...

    In this lesson we want to answer 3 simple questions: 
    - Which latrine depth has the greatest mean number of OTUs?
    - Is there more Clostridia in Tanzania or Vietnam?
    - Which site had the greatest number of bacteria?



How easy is it to answer these questions with the data in this format?

Which tidy data rules might our data frame break?

At first glance we can see that the column names are actually 3 different variables: 'Country', 'LatrineNumber', and 'Depth'. This information will likely be useful in our study, as we expect different bacteria at different depths, sites, and geographical locations. Each of these is a variable and should have its own separate column.

We could keep the column names as the sample names (as they are meaningful to the researcher) and add the extra variable columns, or we could make up sample names (ie. Sample_1) knowing that the information is not being lost, but rather stored in a more useful format.

Some of the Taxa also appear to have an additional variable of information (ie. _Gp1), but not all taxa have this information. We can also make a separate column for this information.

Each result is the same observational unit (ie. relative abundances of bacteria), so having one table is fine.

We can use the `gather()` function to collect our non-variable columns. This will make our dataset 'long' instead of 'wide'. 

First we have to load our libraries. This will include the tidyr package that the gather() function is from.

```{r}
library(tidyverse)
```

Gather takes key-value pairing. We need to provide it with our new columns. The first argument is the 'key'. In this case we want the column names that represent our Sites. The next argument is the 'value' the are our relative abundance values or OTUs. The third argument is all of the columns that we need to gather. You can specify the columns by listing their names or positions. In this example '-' means every column except Taxa.

```{r}
spread_dat <- gather(dat, Site, OTUs, T_2_1:V_9_4)

dat %>% gather(Site, OTUs, T_2_1:V_9_4)
#equivalent to
dat %>% gather(Site, OTUs, 2:82)
#equivalent to
dat %>% gather(Site, OTUs, -Taxa)
#equivalent to
dat %>% gather(Site, OTUs, -1)
```

Note how the dimensions of your dataframe have changed.

Next, we can use the `separate()` function to get the Country, Latrine_Number, and Depth information from our Site column. separate() takes in your dataframe, the name of the column to be split, the name of your new columns, and the character that you want to split the columns  by, in this case an underscore. Note that the defalut is to remove your original column - if you want to keep it, you can add the additional argument `remove = FALSE`, keeping in mind that you now have redundant data. We may also want to do this for the 'Group' of Acidobacteria.

```{r}
split_dat <- spread_dat %>% separate(Site, c("Country", "Latrine_Number", "Depth"), sep = "_")
#equivalent to
split_dat <- spread_dat %>% separate(Site, c("Country", "Latrine_Number", "Depth"), sep = "_", remove = TRUE)

split_dat <- split_dat %>% separate(Taxa, c("Taxa", "Group"), sep = "_Gp")
```
We get a warning from R that it has filled in 'NA' for the bacteria that did not have groups. Note that I chose to split Taxa using '_Gp' since I did not need 'Gp'. 


***
__Challenge__ 


<div style="float:left;margin:0 10px 10px 0" markdown="1">
![](img/pug_challenge1.jpeg){width=100px}

</div>

Use the `glimpse()` function to look  at the type of each variable in our new data frame. Are those the types you expected? Why or why not? How is `glimpse()` different from the `str()` function?

</br>

</br>

***

#Or maybe get them to try a calculation with depth and get them to trouble-shoot??

Let's go back to the questions we wanted to ask at the beginning of the lesson:

Which latrine depth has the greatest mean number of OTUs?


```{r}

split_dat %>% group_by(Latrine_Number) %>% summarize(mean = mean(OTUs)) %>% arrange(desc(mean))

```


Is there more Clostridia in Tanzania or Vietnam?

```{r}
split_dat %>% filter(Taxa == "Clostridia") %>% group_by(Country) %>% summarise(sum = sum(OTUs)) %>% arrange(desc(sum))

```

Which site had the greatest number of bacteria? (Calculate the sum of and the mean of OTUs at for each combination of Country, Latrine_Number and Depth. Order the results by the highest sum, followed by the highest mean.)


```{r}
split_dat %>% group_by(Country, Latrine_Number, Depth) %>% summarize(sum = sum(OTUs), mean = mean(OTUs)) %>% arrange(desc(sum), desc(mean))

```





To get data back into its original format, there are reciprocal functions in the tidyr package, making it possible to switch between wide and long formats. 

__Fair question:__ But you've just been telling me how great the 'long' format is?!?! Why would I want the wide format???

__Honest answer:__ Note that our original data frame was 52 rows and expanded to 4212 rows in the long format. When you have, say, a genomics dataset you might end up with 6,000 rows expanding to 600,000 rows. You probably want to do your calculations and switch back to the more 'human readable' format. Sure, I can save a data frame with 600,000 rows, but I can't really send it to anyone because LibreOffice or Excel will crash opening it. Also, sometimes you just can't fight against conventional formatting...and win.


***
__Challenge__ 


<div style="float:left;margin:0 10px 10px 0" markdown="1">
![](img/pug_challenge1.jpeg){width=100px}

</div>

Collapse Country, Latrine_Number and Depth back into one variable, 'Site', using the `unite()' function. Store the output in a data frame called unite_dat.

</br>
</br>

***
__Challenge__ 


<div style="float:left;margin:0 10px 10px 0" markdown="1">
![](img/Pug-vs-Food-1.jpg){width=100px}

</div>

Use the `spread()` function to turn unite_dat into the wide shape of our original dataset. 

</br>
</br>

***

##Adding rows and columns to data frames

We are going to use a subset of a second data frame from the same study to use in our join lesson. We are going to remove some observations and add an observation so the names of the samples we are working with are not exactly equal.

```{r}
jdat <- read.csv("data/ENV_pitlatrine.csv", stringsAsFactors = FALSE)

str(jdat)
```

To remove some observations and variables, we can specify which rows/columns we do/do not want to keep.

```{r}
jdat <- jdat[-c(4,7,9,12,20,22) , 1:4]

```
To add an observation, we need to add a row of data. `rbind()` is a base R function that will add a row to the end of a data frame. 

Public Service Announcement: IF YOU ADD A VECTOR TO YOUR DATA FRAME rbind() does not check to make sure your value belongs to a column and will not throw an error if the length of the added row is longer or shorter than your data frame. For example, I want to add an extra row to my data frame which is in the form of a vector which is supposed to be of length 4 (the number of columns in my data frame). Here, I have simply created a vector with a new sample name, and then have used the `rep()` function to repeat the value 5, 3 times. This is added to the data frame jdat.

```{r}
jdat <- rbind(jdat, c("V_2_10", rep(5, 3)))
tail(jdat)
```
However, if I had created a vector that was too short, the vector would be recycled to match the number of columns in the data frame. We can see that the sample name has been recycled in the TS column.

```{r}
rbind(jdat, c("V_2_10", rep(5, 2))) %>% tail()
```

If the vector is too long, it will simply be truncated to the match the number of columns in the data frame.
```{r}
rbind(jdat, c("V_2_10", rep(5, 16))) %>% tail()
```


If you give rbind() your column information AS A VECTOR, it ignores it. This is the correct column information.

```{r}
rbind(jdat, c(Samples = "V_2_10", pH = 5, Temp = 5, TS = 5)) %>% tail()
```

This is the incorrect column information. Note that the row is added regardless. One other note of importance is that, because vectors must be coerced to one data type, in this case a character vector. We started with both character and numeric data in jdat. In adding a vector, the entire data frame (think of each column as a vector) has been coerced to character data.

```{r}
rbind(jdat, c(Turtles = "V_2_10", pH = 5, Volatility = 5, TS = 5)) %>% tail()
```
This will not happen if you USE A LIST with rbind(), because lists can hold multiple types of data. This is a lesson in using correct data structures. USING A LIST rbind() will warn us appropriately if our row is of an inappropriate length.

```{r error = TRUE}
rbind(jdat, list("V_2_10", rep(5, 16))) %>% tail()
```
And it will warn us when our names do not match.

```{r error = TRUE}
rbind(jdat, list(Turtles = "V_2_10", pH = 5, Volatility = 5, TS = 5)) %>% tail()
```


There is an equivalent function from dplyr, `bind_rows()', which tries to save you from errors by ensuring that your column identifiers match. If you do not give column identifiers, whether you are trying to add a vector or a list, it will not add your row to the frame.

```{r error = TRUE}
bind_rows(jdat, c("V_2_10", rep(5, 2))) %>% tail()
```
```{r error = TRUE}
bind_rows(jdat, list("V_2_10", rep(5, 2))) %>% tail()
```
If you give bind_rows() the correct column information in vector format, it will not add your row. However, it actually gives you the useful error that your character types are not matching. If you character types do match (ie. if our data frame was all character data), the row would be added.

```{r}
bind_rows(jdat, c(Samples = "V_2_10", pH = 5, Temp = 5, TS = 5)) %>% tail()
```

If you give bind_rows() the correct column information in list format, it will add your row.

```{r}
bind_rows(jdat, list(Samples = "V_2_10", pH = 5, Temp = 5, TS = 5)) %>% tail()
```

bind_rows() has a different behaviour than rbind() when column names do not match. It will match your columns as much as possible, and then create new columns for the data that does not fit at the end of your data frame. Not that 'NA's will be created for all missing data.

```{r error = TRUE}
bind_rows(jdat, list(Turtles = "V_2_10", pH = 5, Volatility = 5, TS = 5)) %>% tail()
```
Whenever you are adding rows or columns, I strongly advise checking to see that the dimensions of the resulting data frame are what you expect. 
```{r}
jdat <- bind_rows(jdat, list(Samples = "V_2_10", pH = 5, Temp = 5, TS = 5)) 
dim(jdat)
```



#rbind - correct titles but not in order vs bind rows
#character type the same re:rbind vector


##Intro to joins

Often we have more than one data table that shares a common attribute. For example, with our current dataset, we have other variables (such as pH) for a sample, as well as our OTU table, both of which have site IDs (ie. T_2_9). We want to mergee these into one table.


Joins can be tricky, so we are going to use a subset of our tidy data such that we can easily observe the output of our join.

```{r}
str(spread_dat)
```
When we look at our data frames we can see that they have matching information in 'Samples'. This is the 'key' that we can match up our data frames by. We are going to reduce our dataset by only keeping non-zero values so we can see how the join functions work a bit more easily. We have already removed some observations from jdat and added a row, just so our key columns don't match perfectly.

***
__Challenge__ 


<div style="float:left;margin:0 10px 10px 0" markdown="1">
![](img/pug_challenge1.jpeg){width=100px}

</div>

Filter spread_dat to remove all non-zero values, and store it in an object ndat. How many rows in spread_dat had the value of zero? Sort ndat to keep the top 20 rows with the highest OTUs.

</br>

</br>

***

There are 2 types of joins:
- mutating joins - uses a key to match observations and combines variables from 2 tables (adding columns and potentially rows)
- filtering joins - uses a key to match observations, to subset observations (rows)


Inner join is a mutating join.  Inner join "returns all rows from x where there are matching values in y, and all columns from x and y. If there are multiple matches between x and y, all combination of the matches are returned."

A set of graphics from R for Data Science makes the description clearer:
![](img/join-inner.png)  


```{r}

inner_join(ndat, jdat, by = c("Site" = "Samples"))

```

We can see that there are 18 rows in the resulting data frame. and that columns from jdat have been added. Rows from ndat that did not have a matching site in jdat were removed.

Outer joins are a set of mutating joins. There are 3 outer joins: left, right, and full.
![](img/join-outer.png)


left_join() return all rows from x, and all columns from x and y. Rows in x with no match in y will have NA values in the new columns. If there are multiple matches between x and y, all combinations of the matches are returned.


```{r}

left_join(ndat, jdat, by = c("Site" = "Samples"))

```
That means that we will have our 20 rows from ndat, and any items that weren't found in jdat, in this case T_2_2 and T_4_3 will be filled with NA.

right_join() "returns all rows from y, and all columns from x and y. Rows in y with no match in x will have NA values in the new columns. If there are multiple matches between x and y, all combinations of the matches are returned."

```{r}

right_join(ndat, jdat, by = c("Site" = "Samples"))

```

That means that we will have our 75 rows from jdat, and any items that weren't found in ndat will be filled with NA. Since there are 76 rows in the final data frame, this means there must have been multiple rows matching from ndat. In other words, we had a duplicate key (Site) in ndat.

![](img/join-one-to-many.png)


Let's try to find which Site was duplicated. n() is a special dplyr function that counts the number of observations in a group. It can also be used with summarize() and mutate().

```{r}
right_join(ndat, jdat, by = c("Site" = "Samples")) %>% 
  group_by(Site) %>% 
  filter(n()>1)

```

Note that Bacteriodia and Clostridia have different OTUs (from ndat), but the same pH, Temp and TS (from jdat). 


***
__Challenge__
<div style="float:left;margin:0 10px 10px 0" markdown="1">
![](img/pug_challenge1.jpeg){width=100px}

</div>

Use mutate() and summarise() with n() to find the duplicated Site.

</br>

</br>

***

Note that if both of our data frames had duplicated keys, all possible matches would be retruned.

![](img/join-many-to-many.png)


full_join "returns all rows and all columns from both x and y. Where there are not matching values, returns NA for the one missing."


```{r}

full_join(ndat, jdat, by = c("Site" = "Samples"))

```
The full join returns all of the rows from both ndat and jdat - we have the 75 rows from jdat, plus the second V_17_1 as seen in the right_join and T_2_2 and T_4_3 that we present in ndat but NA in jdat for a total of 78 rows.

Lastly, we have the 2 filtering joins. These will not add columns, but rather filter the rows based on what is present in the second data frame.

semi_join() "returns all rows from x where there are matching values in y, keeping just columns from x. A semi join differs from an inner join because an inner join will return one row of x for each matching row of y, where a semi join will never duplicate rows of x."

```{r}
semi_join(ndat, jdat, by = c("Site" = "Samples"))

```
semi_join() returns the 18 rows of ndat that have a Site match in jdat. Note that the columns from jdat have not been added.

anti_join() "returns all rows from x where there are not matching values in y, keeping just columns from x."

```{r}
anti_join(ndat, jdat, by = c("Site" = "Samples"))

```
This returns our 2 rows in ndat that did not have a match in jdat. Note that the columns from jdat have not been added.

***
__Challenge__
<div style="float:left;margin:0 10px 10px 0" markdown="1">
![](img/pug_challenge1.jpeg){width=100px}

</div>

Given the definitions for the inner_, left_, right_, full_, semi_ and anti_joins, what would you expect the resulting data frame to be if jdat and ndat were reversed? Write down the number of rows and columns you would expect the data frame to have, then run the code. Did you find any surprises?

</br>

</br>

***

__Challenge__
<div style="float:left;margin:0 10px 10px 0" markdown="1">
![](img/pug_challenge1.jpeg){width=100px}

</div>

Base R has a function that does join operations called `merge()`. What would be the code equivalent to the left_join of ndat and jdat? 

</br>

</br>

***
- merging/adding data 
      + join/merge functions
      
http://stat545.com/bit001_dplyr-cheatsheet.html
http://dplyr.tidyverse.org/articles/two-table.html
http://r4ds.had.co.nz/relational-data.html#join-problems

      + binding functions with caveats
      
_Simple Statistics_
  

 + using summarize() to get mean, median, modes, quantiles and standard deviations, variance, skew

    
- revisitng the apply() function

- performing t-tests in R
        
__Challenge:__     
Take one of the provided test sets and calculate an average that requires subsetting and grouping. Perhaps make a separate question for say, a choice of 4 datasets (cars, iris, gapminder, lotr). (Add t-test question with the gapminder dataset).
  
#Resources:  
http://seananderson.ca/2013/10/19/reshape.html     
https://github.com/wmhall/tidyr_lesson/blob/master/tidyr_lesson.md     
http://stat545.com/block009_dplyr-intro.html     
http://stat545.com/block010_dplyr-end-single-table.html
http://vita.had.co.nz/papers/tidy-data.pdf
https://thinkr.fr/tidyverse-hadleyverse/


#Post-Lesson Assessment
***

Your feedback is essential to help the next cohort of trainees. Please take a minute to complete the following short survey:
https://www.surveymonkey.com/r/GD3KJB9

</br>

***

</br>

Thanks for coming!!!

![](img/rstudio-bomb.png){width=300px}


